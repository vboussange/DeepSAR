{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSAR demo\n",
    "\n",
    "This notebook demonstrates the workflow for running DeepSAR, including model initialization, data processing, prediction, and visualization of species richness.\n",
    "\n",
    "In Colab, please choose under \"Resources\" a GPU environment.\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1063,
     "status": "ok",
     "timestamp": 1752674067119,
     "user": {
      "displayName": "Victor Boussange",
      "userId": "00770729539785020088"
     },
     "user_tz": -120
    },
    "id": "adv5uMPsTfiR",
    "outputId": "c473e6d4-03ad-48cf-b447-a1809cc84bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'deepsar' already exists and is not an empty directory.\n",
      "\u001b[2mResolved \u001b[1m99 packages\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.93ms\u001b[0m\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdeepsar\u001b[0m\u001b[2m==0.1.0 (from file:///home/boussang/NNSAR)\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m94 packages\u001b[0m \u001b[2min 167ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepsar\u001b[2m @ file:///home/boussang/NNSAR\u001b[0m                      \n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepsar\u001b[2m @ file:///home/boussang/NNSAR\u001b[0m              \u001b[1A\n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepsar\u001b[2m @ file:///home/boussang/NNSAR\u001b[0m              \u001b[1A\n",
      "\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m deepsar\u001b[2m @ file:///home/boussang/NNSAR\u001b[0m              \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 549ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0mm file:///home/boussang/NNSAR)    \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdeepsar\u001b[0m\u001b[2m==0.1.0 (from file:///home/boussang/NNSAR)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vboussange/deepsar.git\n",
    "!cd deepsar\n",
    "!uv sync\n",
    "!uv pip install torch --torch-backend=auto\n",
    "!uv pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1752673872667,
     "user": {
      "displayName": "Victor Boussange",
      "userId": "00770729539785020088"
     },
     "user_tz": -120
    },
    "id": "3B-M0MHtfxwU",
    "outputId": "80952be6-85d3-4a0b-e085-b61949afa83f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxr\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepsar\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_processing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils_env_pred\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CHELSADataset\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'train'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from train import Config\n",
    "from pathlib import Path\n",
    "from deepsar.data_processing.utils_env_pred import CHELSADataset\n",
    "from deepsar.neural_4pweibull import initialize_ensemble_model\n",
    "from deepsar.plotting import CMAP_BR\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_raster(X_map, ypred):\n",
    "    Xy_map = X_map.copy()\n",
    "    Xy_map[\"pred\"] = ypred\n",
    "    rast = Xy_map[\"pred\"].to_xarray().sortby([\"y\",\"x\"])\n",
    "    rast = xr.DataArray(rast.values, dims=[\"y\", \"x\"], coords={\n",
    "                            \"x\": rast.x.values,  # X coordinates (easting)\n",
    "                            \"y\": rast.y.values,  # Y coordinates (northing)\n",
    "                        },\n",
    "                        name=\"pred\")\n",
    "    rast = rast.rio.write_crs(\"EPSG:3035\")\n",
    "    return rast\n",
    "\n",
    "def plot_raster(rast, label, ax, cmap, vmin=None, vmax=None):\n",
    "        # world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "        # world.boundary.plot(ax=ax, linewidth=0.1, edgecolor='black')\n",
    "        cbar_kwargs = {'orientation':'horizontal', 'shrink':0.6, 'aspect':40, \"label\":\"\",\"pad\":0.05, \"location\":\"bottom\"} #if display_cbar else {}\n",
    "        # rolling window for smoothing\n",
    "        rast.where(rast > 0.).plot(ax=ax,\n",
    "                                    cmap=cmap,\n",
    "                                    cbar_kwargs=cbar_kwargs,\n",
    "                                    vmin=vmin,\n",
    "                                    vmax=vmax)\n",
    "        ax.set_title(label)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "\n",
    "def create_features(predictor_labels, climate_dataset, res):\n",
    "    # see: https://docs.xarray.dev/en/stable/generated/xarray.DataArray.coarsen.html\n",
    "    resolution = abs(climate_dataset.rio.resolution()[0])\n",
    "    ncells = max(1, int(res / resolution))\n",
    "    coarse = climate_dataset.coarsen(x=ncells, y=ncells, boundary=\"trim\")\n",
    "\n",
    "    # See: https://corteva.github.io/rioxarray/stable/rioxarray.html#rioxarray.raster_array.RasterArray.reproject_match\n",
    "    coarse_mean = coarse.mean().rio.write_crs(\"EPSG:3035\")#.rio.reproject_match(ref)\n",
    "    coarse_std = coarse.std().rio.write_crs(\"EPSG:3035\")#.rio.reproject_match(ref)\n",
    "    df_mean = coarse_mean.to_dataframe()\n",
    "    df_std = coarse_std.to_dataframe()\n",
    "    df_std = df_std.rename({col: \"std_\" + col for col in df_std.columns}, axis=1)\n",
    "    X_map = pd.concat([df_mean, df_std], axis=1)\n",
    "\n",
    "    X_map = X_map.assign(log_observed_area=np.log(res**2), log_megaplot_area=np.log(res**2))\n",
    "    return X_map[predictor_labels]\n",
    "\n",
    "# we use batches, otherwise model and data may not fit in memory\n",
    "def get_SR_std_SR(model, climate_dataset, res, predictors, feature_scaler, target_scaler, batch_size=4096):\n",
    "    \"\"\"\n",
    "    Calculate SR, std_SR and dlogSR_dlogA for the given model and climate\n",
    "    dataset at a specified resolution. dSR is obtained as a gradient of SR with\n",
    "    respect to log_megaplot_area. Does not account for changes in climate\n",
    "    features with area.\n",
    "    \"\"\"\n",
    "    mean_SR_list = []\n",
    "    std_SR_list = []\n",
    "    features = create_features(predictors, climate_dataset, res)\n",
    "    total_length = len(features)\n",
    "\n",
    "    percent_step = max(1, total_length // batch_size // 100)\n",
    "\n",
    "    for i in tqdm(range(0, total_length, batch_size), desc = \"Calculating SR and stdSR\", miniters=percent_step, maxinterval=float(\"inf\")):\n",
    "        with torch.no_grad():\n",
    "            current_batch_size = min(batch_size, total_length - i)\n",
    "            # features = get_true_sar.interpolate_features(X_map_dict, log_area_tensor, res_climate_pixel, predictors, batch_index=slice(i, i + current_batch_size))\n",
    "            X = features.iloc[i:i+current_batch_size,:]\n",
    "            X = feature_scaler.transform(X.values)\n",
    "            X = torch.tensor(X, dtype=torch.float32).to(next(model.parameters()).device)\n",
    "            ys = [m.predict_sr(X[:, 1:]) for m in model.models] # predicting asymptote, no need to feed log_observed_area\n",
    "            SRs = [target_scaler.inverse_transform(y.cpu().numpy()) for y in ys]\n",
    "            mean_SR = np.mean(SRs, axis=0)\n",
    "            std_SR = np.std(SRs, axis=0)\n",
    "            mean_SR_list.append(mean_SR)\n",
    "            std_SR_list.append(std_SR)\n",
    "\n",
    "    mean_SR = np.concatenate(mean_SR_list, axis=0)\n",
    "    std_SR = np.concatenate(std_SR_list, axis=0)\n",
    "    return features, mean_SR, std_SR\n",
    "\n",
    "\n",
    "def load_chelsa_and_reproject(predictors):\n",
    "    climate_dataset = xr.open_dataset(CHELSADataset().cache_path)\n",
    "    climate_dataset = climate_dataset[[v for v in climate_dataset.data_vars if v in predictors]]\n",
    "    climate_dataset = climate_dataset.rio.reproject(\"EPSG:3035\")\n",
    "    return climate_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jRaM85OgeBz"
   },
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"0b85791\"\n",
    "plotting = True\n",
    "\n",
    "path_results = Path(__file__).parent / Path(f\"results/train/deepsar_ensemble_weights_{MODEL_NAME}.pth\")\n",
    "results_fit_split = torch.load(path_results, map_location=\"cpu\")\n",
    "config = results_fit_split[\"config\"]\n",
    "\n",
    "predictors = results_fit_split[\"predictors\"]\n",
    "feature_scaler = results_fit_split[\"feature_scaler\"]\n",
    "target_scaler = results_fit_split[\"target_scaler\"]\n",
    "\n",
    "model = initialize_ensemble_model(results_fit_split[\"ensemble_model_state_dict\"], predictors, config)\n",
    "climate_dataset = load_chelsa_and_reproject(predictors)\n",
    "res = 1000\n",
    "\n",
    "features, SR, std_SR = get_SR_std_SR(model, climate_dataset, res, predictors, feature_scaler, target_scaler)\n",
    "\n",
    "SR_rast = create_raster(features, SR)\n",
    "SR_rast.rio.to_raster(f\"SR_raster_{MODEL_NAME}_{res:.0f}m.tif\")\n",
    "if plotting:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import cm\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    # colors = [\"#dad7cd\",\"#a3b18a\",\"#588157\",\"#3a5a40\",\"#344e41\"]\n",
    "    SR_rast = SR_rast.rename(\"SR\")\n",
    "    SR_rast.plot(ax=ax, cmap=CMAP_BR, vmin=SR_rast.quantile(0.01), vmax=SR_rast.quantile(0.99))\n",
    "    ax.set_title(f\"Res: {res}m\")\n",
    "    fig.savefig(f\"SR_raster_{MODEL_NAME}_{res:.0f}m.png\", dpi=300, bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPgHul+sTZIIdp+MUmiiRcF",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deepsar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
